---
title: "Parameter calibration: likelihood methods"
format: 
  html:
      embed-resources: true
editor: visual
---

## Problem set

You will be asked submit (via Canvas) your rendered (or knitted) html document

```{r}
library(tidyverse)
```

### Part 1

Load dataset

```{r}
d <- read_csv(file = "https://data.ecoforecast.org/neon4cast-targets/phenology/phenology-targets.csv.gz", show_col_types = FALSE)
```

Filter the dataset to only include the site_id BART (Bartlett Experimental Forest in the White Mountains of New Hampshire) and the dates between 2019-01-01 and 2019-07-01. Convert the date to Day of Year (hint: use `lubridate:: yday()` function). Remove rows with gcc_90 equal to NA or gcc_sd equal to 0.

```{r}
bart_2019 <- d  %>%
  filter(site_id == "BART",
         datetime > as_date("2019-01-01"),
         datetime < as_date("2019-07-01"),
         variable == "gcc_90") %>%
  mutate(doy = yday(datetime)) %>% 
  filter(!is.na(observation),
         observation > 0)
```

**Question 1:** How is gcc_90 related to day of year?

**Answer 1:** gcc_90 is the 90th percentile of GCC on a given day of the year. For each day of year, gcc_90 returns the value for the 90th percentile of all GCC values that day. 
Specifically, according to @fig-gcc_dt, gcc_90 remains relatively constant from the winter to summer, then gcc_90 increases quickly at the beginning of summer. GCC quantifies greenness, so it makes sense that GCC would increase when the trees would leaf out, which would be summertime in New Hampshire. 

```{r}
#| echo: false
#| fig-cap: Relationship between gcc_90 and datetime
#| label: fig-gcc_dt
ggplot(bart_2019) + 
  geom_point(aes(x=datetime, y=observation))+
  theme_bw()+
  ylab("gcc_90")
```

**Question 2:** Use a histogram to examine the distribution of the gcc_90

**Answer 2:** gcc_90 is not normally distributed. In fact, according to @fig-hist_gcc, gcc_90 is heavily right-skewed for this time frame. 

```{r}
#| echo: false
#| fig-cap: Histogram of gcc_90 values
#| label: fig-hist_gcc
hist(bart_2019$observation, main = "", xlab = "gcc_90")
```

First create a function called \`pred_logistic' that is your process model. The model is the the logistic curve which is the equation $$P_1 + P_2 {{exp(P_3 + P_4 x)}\over{1+exp(P_3 + P_4 x)}}$$

**Question 3:** Is this process model a dynamic model? Why or why not?

**Answer 3:** This process model is not a dynamic model because it does not depend on the previous model state. 

**Question 4:** Based on the equation above, write a function that predicts the gcc_90 as a function of the parameters ($P$) and x where x is the DOY. Name that function `pred_logistic`.

**Answer 4:**

```{r}
pred_logistic<-function(x, par){
  y<-par[1] + par[2] * (exp(par[3] + par[4]*x)/(1+exp(par[3] + par[4]*x)))
}
```

**Question 5:** Write a function that calculates the negative log-likelihood of the data given a set of parameters governing the process and data models. Assume a normal distribution and be sure to estimate the sd in the data model.

**Answer 5:**

```{r}
LL_fn <- function(par, x, y){
  -sum(dnorm(y, mean = pred_logistic(x, par), sd = par[5], log = TRUE))
}
```

**Question 6:** Use the `optim` function to find the most likely parameter values. Use the following as starting values `par = c(0.34,0.11,-15,0.11, 1)` where the first four are the theta parameters from your process model and the fifth is the sd of your data model.

**Answer 6:**

```{r}
fit <- optim(par = c(0.34,0.11,-15,0.11, 1), fn = LL_fn, method = "BFGS", x = bart_2019$doy, y = bart_2019$observation)
```

**Question 7:** Use your optimal parameters in the `pred_logistic` function to predict the data. Save this as the object `predicted`

**Answer 7:**

```{r}
predicted<-pred_logistic(bart_2019$doy, fit$par)

ggplot()+
  geom_point(data=bart_2019, aes(x=doy, y=observation))+
  geom_line(aes(x=bart_2019$doy, y=pred_logistic(x=bart_2019$doy, par=fit$par)))
```

**Question 8:** Calculate the residuals and plot a histogram of the residuals

**Answer 8:**

```{r}
residuals <- predicted - bart_2019$observation

#| echo: false
#| fig-cap: Histogram of gcc_90 residual values
#| label: fig-hist_gccres
hist(residuals, main = "", xlab = "gcc_90 residuals")
```

**Question 9:** How does the distribution of the data (Question 2) compare to the distribution of the residuals?

**Answer 9:** The data are not normally distributed, but the residuals are relatively normally distributed. 

**Question 10:** Predict year 2020 using the process model parameters from the 2019 fit.

```{r}
#Add Answer
```

**Answer 10:**

**Question 11:** Plot the forecast from Question 10 over the data from 2020 (I give the code for getting the 2020 data)

**Answer 11:**

```{r}
bart_2020 <- d  %>%
  filter(site_id == "BART",
         datetime > as_date("2020-01-01"),
         datetime < as_date("2020-07-01"),
         variable == "gcc_90") %>%
  mutate(doy = yday(datetime)) %>% 
  filter(!is.na(observation),
         observation > 0)
```

**Question 12:** Do you think your model from 2019 is reasonable for predicting 2020?

**Answer 12:**

### Part 2 {#sec-q10}

Using the following data

```{r}
df <- read_csv("https://raw.githubusercontent.com/frec-5174/eco4cast-in-R-book/main/data/soil_respiration_module_data.csv", show_col_types = FALSE)
```

It is a dataset that reports soil respiration, soil temperature, and soil moisture over a year at the University of Michigan Biological Station (from Nave, L.E., N. Bader, and J.L. Klug)

The columns correspond to the following

-   doy = Day of Year\
-   soil_resp: Soil respiration (micromoles CO2 per m2 per second)\
-   soil_temp: Soil Temp (deg C) soil_moisture: Soil Moisture (%)\

Use maximum likelihood to estimate the parameters in the model that predicts the relationship between soil temperature and soil respiration using the Q10 function below

$$\theta_1 * \theta_2 ^{{(T - 20)}\over{10}}$$

Show all the steps to determine the most likely parameter values, report the parameter values, and plot the data and predictions on the same plot
